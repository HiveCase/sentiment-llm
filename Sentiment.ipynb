{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiwlHUdAhkqmQ9F2GTogaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HiveCase/sentiment-llm/blob/main/Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem_Statement\n",
        "DataSentinel Inc. is a tech company specializing in building advanced natural language processing (NLP) solutions. Their latest project involves integrating an AI-powered sentiment analysis module into an internal monitoring dashboard. The goal is to automatically classify large volumes of unstructured feedback and text data from various sources as either GOOD, BAD, or NEUTRAL. As part of the quality assurance process, the development team needs to test the integration with a series of sample inputs—even ones that may not represent coherent text—to ensure that the system routes and processes the data correctly.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Before rolling out the live system, the team creates a test harness using Python. The harness employs the httpx library to send POST requests to OpenAI's API. For this proof-of-concept, the team uses the dummy model gpt-4o-mini along with a dummy API key in the Authorization header to simulate real API calls.\n",
        "\n",
        "One of the test cases involves sending a sample piece of meaningless text:<br>\n",
        "```\n",
        "7bch3HkLboJSd Cy9SY8J j9vVugK8yqygNhJXa sR HT 4 rU\n",
        "```\n",
        "---\n",
        "Write a Python program that uses httpx to send a POST request to OpenAI's API to analyze the sentiment of this (meaningless) text into GOOD, BAD or NEUTRAL. Specifically:\n",
        "\n",
        "1. Make sure you pass an Authorization header with dummy API key.\n",
        "2. Use ***gpt-4o-mini*** as the model.\n",
        "3. The first message must be a system message asking the LLM to analyze the sentiment of the text. Make sure you mention GOOD, BAD, or NEUTRAL as the categories.\n",
        "4. The second message must be exactly the text contained above.\n",
        "---\n",
        "\n",
        "This test is crucial for DataSentinel Inc. as it validates both the API integration and the correctness of message formatting in a controlled environment. Once verified, the same mechanism will be used to process genuine customer feedback, ensuring that the sentiment analysis module reliably categorizes data as GOOD, BAD, or NEUTRAL. This reliability is essential for maintaining high operational standards and swift response times in real-world applications.\n",
        "\n",
        "**Note:** This uses a dummy httpx library, not the real one. You can only use:\n",
        "\n",
        "\n",
        "\n",
        "1.   response = httpx.get(url, **kwargs)\n",
        "2.   response = httpx.post(url, json=None, **kwargs)\n",
        "3.   response.raise_for_status()\n",
        "4.   response.json()"
      ],
      "metadata": {
        "id": "-pFxHi2_0sRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('AIPROXY_TOKEN')\n",
        "text = '7bch3HkLboJSd Cy9SY8J j9vVugK8yqygNhJXa sR HT 4 rU'"
      ],
      "metadata": {
        "id": "Jnq6B1Z30rpc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PiGL-LZB0ofb",
        "outputId": "5bee2fce-9b86-40d6-8a1e-7c64a836dece"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'object': 'list',\n",
              " 'data': [{'id': 'tts-1',\n",
              "   'object': 'model',\n",
              "   'created': 1681940951,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'tts-1-1106',\n",
              "   'object': 'model',\n",
              "   'created': 1699053241,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'dall-e-2',\n",
              "   'object': 'model',\n",
              "   'created': 1698798177,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'whisper-1',\n",
              "   'object': 'model',\n",
              "   'created': 1677532384,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'gpt-3.5-turbo-instruct',\n",
              "   'object': 'model',\n",
              "   'created': 1692901427,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4o-mini',\n",
              "   'object': 'model',\n",
              "   'created': 1721172741,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo',\n",
              "   'object': 'model',\n",
              "   'created': 1677610602,\n",
              "   'owned_by': 'openai'},\n",
              "  {'id': 'gpt-3.5-turbo-0125',\n",
              "   'object': 'model',\n",
              "   'created': 1706048358,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'babbage-002',\n",
              "   'object': 'model',\n",
              "   'created': 1692634615,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'davinci-002',\n",
              "   'object': 'model',\n",
              "   'created': 1692634301,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'dall-e-3',\n",
              "   'object': 'model',\n",
              "   'created': 1698785189,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'text-embedding-ada-002',\n",
              "   'object': 'model',\n",
              "   'created': 1671217299,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'gpt-3.5-turbo-16k',\n",
              "   'object': 'model',\n",
              "   'created': 1683758102,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'gpt-4o-mini-2024-07-18',\n",
              "   'object': 'model',\n",
              "   'created': 1721172717,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'text-embedding-3-small',\n",
              "   'object': 'model',\n",
              "   'created': 1705948997,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'text-embedding-3-large',\n",
              "   'object': 'model',\n",
              "   'created': 1705953180,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'tts-1-hd',\n",
              "   'object': 'model',\n",
              "   'created': 1699046015,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'tts-1-hd-1106',\n",
              "   'object': 'model',\n",
              "   'created': 1699053533,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo-1106',\n",
              "   'object': 'model',\n",
              "   'created': 1698959748,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo-instruct-0914',\n",
              "   'object': 'model',\n",
              "   'created': 1694122472,\n",
              "   'owned_by': 'system'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "response = httpx.get('https://aiproxy.sanand.workers.dev/openai/v1/models',headers = {\"Authorization\":f\"Bearer {api_key}\"})\n",
        "response.json()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = httpx.post('http://aiproxy.sanand.workers.dev/openai/v1/chat/completions',\n",
        "                      headers={\"Authorization\":f\"Bearer {api_key}\"},\n",
        "                      json={\n",
        "                          \"model\":\"gpt-4o-mini\",\n",
        "                          \"messages\":[\n",
        "                              {\"role\":\"system\",\"content\":\"classify large volumes of unstructured feedback and text data from various sources as either GOOD, BAD, or NEUTRAL\"},\n",
        "                              {\"role\":\"user\",\"content\":text}\n",
        "                          ]\n",
        "                      })\n",
        "response.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCs6z_TG2XH1",
        "outputId": "eb1fcec1-d9e7-4e96-8c3d-a210e5e02360"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-BcAD6OsriT5vZG8vvtfzyYsUlrRjM',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1748435412,\n",
              " 'model': 'gpt-4o-mini-2024-07-18',\n",
              " 'choices': [{'index': 0,\n",
              "   'message': {'role': 'assistant',\n",
              "    'content': 'NEUTRAL',\n",
              "    'refusal': None,\n",
              "    'annotations': []},\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'stop'}],\n",
              " 'usage': {'prompt_tokens': 70,\n",
              "  'completion_tokens': 3,\n",
              "  'total_tokens': 73,\n",
              "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
              "  'completion_tokens_details': {'reasoning_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'accepted_prediction_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0}},\n",
              " 'service_tier': 'default',\n",
              " 'system_fingerprint': 'fp_34a54ae93c',\n",
              " 'monthlyCost': 0.01458904,\n",
              " 'cost': 0.000228,\n",
              " 'monthlyRequests': 56,\n",
              " 'costError': 'crypto.createHash is not a function'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.json()['choices'][0]['message']['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8NcP-Qcb4ILc",
        "outputId": "10fbd078-11de-41a9-d90e-086d816f1871"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEUTRAL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJTzSxVR53Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consolidated code\n",
        "import httpx\n",
        "text = '7bch3HkLboJSd Cy9SY8J j9vVugK8yqygNhJXa sR HT 4 rU'\n",
        "response = httpx.post('http://aiproxy.sanand.workers.dev/openai/v1/chat/completions',\n",
        "                      headers={\"Authorization\":\"Bearer dummy_api_key\"},\n",
        "                      json={\n",
        "                          \"model\":\"gpt-4o-mini\",\n",
        "                          \"messages\":[\n",
        "                              {\"role\":\"system\",\"content\":\"classify large volumes of unstructured feedback and text data from various sources as either GOOD, BAD, or NEUTRAL\"},\n",
        "                              {\"role\":\"user\",\"content\":text}\n",
        "                          ]\n",
        "                      })\n",
        "response.json()['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "7m5FwULz3x1j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}